{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autocorrect Spelling Checker.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "17POe2uI2-6LMGZAdZiCchq4-zqt__hSO",
      "authorship_tag": "ABX9TyPULU7Oqg0Jut+0CyJ1yekx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkoday/Autocorrect/blob/main/Autocorrect_Spelling_Checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RdoXmrfjGKx"
      },
      "source": [
        "\r\n",
        "Steps for implementing a very simple autocorrect system without using any deep neural network. Some times a very simple easy solution outperforms a complex one!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t11UKSw9jPcN"
      },
      "source": [
        "1. Identify the mispelled word. A word is mispelled if it is not found in the vocabulary of the corpus of text the autocorrect system is working with.\r\n",
        "2. Perform edit operations in order to find strings that are n edit distance away from the mispelled word.\r\n",
        "3. Filter our the words to retain only the ones found in the vocabulary\r\n",
        "4. Order words based on probability. The probabilities of a word is calculated on the following formula : p(w) = C(w)/V, where \r\n",
        "p(w) is the probability of a word w,\r\n",
        "C(w) is the number of times a word w is appered in the training corpus,\r\n",
        "v is the total no of words in the corpus\r\n",
        "5. Choose the most likely word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62jmrf6igrwo"
      },
      "source": [
        "import re\r\n",
        "import string\r\n",
        "from collections import Counter\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Autocorrect():\r\n",
        "\r\n",
        "\r\n",
        "  def __init__(self,corpus_file):\r\n",
        "    with open(corpus_file , 'r') as file:\r\n",
        "      lines = file.readlines()\r\n",
        "      words=[]\r\n",
        "      for line in lines:\r\n",
        "        words+= re.findall(r'\\w+',line.lower()) ## total no of words present in my corpus\r\n",
        "        \r\n",
        "\r\n",
        "    self.unq_words = set(words)   ## Evaluating only the unique words present in my corpus\r\n",
        "    words_counter = Counter(words)  ## Calculating frequency of each word present in the corpus\r\n",
        "    total_words=float(sum(words_counter.values()))\r\n",
        "    self.word_probability = { key:words_counter[key] / total_words  for key in words_counter.keys()} ## probability of each word based on its occurrence in the corpus\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def edit_one_distance(self,word):\r\n",
        "    '''\r\n",
        "    performing edit operations such as split,insert,delete,swap and replace in order to find list of words that are One-edit-distance \r\n",
        "    away from a given word.\r\n",
        "\r\n",
        "    '''\r\n",
        "    eng_letters = string.ascii_lowercase\r\n",
        "    split_word = [(word[:i],word[i:]) for i in range(len(word)+1)]\r\n",
        "    insert_word = [i+c+r for i,r in split_word if r for c in eng_letters]\r\n",
        "    delete_word = [i+r[1:] for i,r in split_word if r]\r\n",
        "    swap_word = [i+r[1]+r[0]+r[2:] for i,r in split_word if len(r)>1]\r\n",
        "    replace_word = [i+c+r[1:] for i,r in split_word for c in eng_letters]\r\n",
        "\r\n",
        "    return set(insert_word + delete_word + swap_word + replace_word)\r\n",
        "\r\n",
        "  def edit_two_distance(self,word):\r\n",
        "    '''\r\n",
        "    With the help of edit_one_distance function and list comprehension we can easily find out words that are Two-edit-distance away from a given word\r\n",
        "\r\n",
        "    '''\r\n",
        "\r\n",
        "    return set(e2 for e1 in edit_one_distance(word) for e2 in edit_one_distance(e1))\r\n",
        "\r\n",
        "\r\n",
        "  def corrections(self, word):\r\n",
        "\r\n",
        "    '''\r\n",
        "    Here we are collecting all possible suggestions that are max Two-edit_distance away from a given word and removing the ones which are not \r\n",
        "    present in my corpus data.\r\n",
        "    The words which are valid and are max Two-edit-distance away from a given mispelled word is stored in best_guesses.\r\n",
        "    and we are suggesting valid words based on their probability\r\n",
        "\r\n",
        "    '''\r\n",
        "    suggestions = self.edit_one_distance(word) or self.edit_two_distance(word) or [word]\r\n",
        "    best_guesses = [w for w in suggestions if w in self.unq_words]\r\n",
        "    return sorted([(w , self.word_probability[w]) for w in best_guesses], key= lambda tup:tup[1],reverse=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0f9gMb4uJDF",
        "outputId": "02bf8764-4f70-4b38-d04e-e25ddadc059b"
      },
      "source": [
        "checker = Autocorrect(\"file_path\")\r\n",
        "checker.corrections('loue')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 0.001193993549118186),\n",
              " ('loud', 7.186072286359452e-05),\n",
              " ('lose', 4.6985857256965655e-05),\n",
              " ('lore', 2.763873956292097e-06)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ShBm4AM4-3V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}